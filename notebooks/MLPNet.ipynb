{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.initializers import he_uniform\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "seed=11\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_predictions(X, y):\n",
    "    I = np.random.permutation(X.shape[0])[:3]\n",
    "\n",
    "    for c, i in enumerate(I):\n",
    "        img = X[i].reshape(28, 28)\n",
    "        plt.subplot(131+c)\n",
    "        plt.imshow(img, cmap=plt.cm.gray)\n",
    "        plt.title(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_history(history):\n",
    "    acc_list = history.history['acc']\n",
    "    acc = acc_list[-1]\n",
    "    best_acc_index = np.array(acc_list).argmax()\n",
    "    best_acc = acc_list[best_acc_index]\n",
    "    \n",
    "    print('Accuracy: {:.4f} \\tBest Accuracy: {:.4f} \\t\\t@ {} epoch'.format(acc, best_acc, best_acc_index+1))\n",
    "    \n",
    "    if 'val_acc' in  history.history.keys():\n",
    "        val_acc_list = history.history['val_acc']\n",
    "        val_acc = val_acc_list[-1]\n",
    "        best_val_acc_index = np.array(val_acc_list).argmax()\n",
    "        best_val_acc = val_acc_list[best_val_acc_index]\n",
    "        print('Dev Accuracy: {:.4f} \\tBest Dev Accuracy: {:.4f} \\t@ {} epoch'.format(val_acc, best_val_acc, best_val_acc_index+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(15,4))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history['acc'], label='Training Set')\n",
    "    \n",
    "    if 'val_acc' in history.history.keys():\n",
    "        plt.plot(history.history['val_acc'], label='Validation Set')\n",
    "    plt.title('Accuracy vs Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history['loss'], label='Training Set')\n",
    "    \n",
    "    if 'val_loss' in history.history.keys():\n",
    "        plt.plot(history.history['val_loss'], label='Validation Set')\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.xlabel('Loss')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_matrix(cm):\n",
    "    row_sum = cm.sum(axis=1, keepdims=True)\n",
    "    norm_cm = cm/row_sum\n",
    "    \n",
    "    np.fill_diagonal(norm_cm, 0)\n",
    "    sns.heatmap(norm_cm, robust=True, fmt=\"f\", cmap='RdBu_r', vmin=0, vmax=4)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_dir = '../payload/'\n",
    "payload_file = 'normal-payload.npz'\n",
    "\n",
    "payload_path = os.path.join(payload_dir, payload_file)\n",
    "\n",
    "payload_archive = np.load(payload_path)\n",
    "\n",
    "dev_set = payload_archive['dev_set']\n",
    "test_set = payload_archive['test_set']\n",
    "train_dev_set = payload_archive['train_dev_set']\n",
    "train_set = payload_archive['train_set']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainy = train_set[:,1:], train_set[:,0]\n",
    "trainY = np_utils.to_categorical(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_devX, train_devy = train_dev_set[:,1:], train_dev_set[:,0]\n",
    "train_devY = np_utils.to_categorical(train_devy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testy = test_set[:,1:], test_set[:,0]\n",
    "testY = np_utils.to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devX, devy = dev_set[:,1:], dev_set[:,0]\n",
    "devY = np_utils.to_categorical(devy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 The Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = .2\n",
    "lambd = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Optimization Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.1 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-4\n",
    "lr_decay = 1e-3\n",
    "batch_size=128\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "models_dir = '../models'\n",
    "modelpath = os.path.join(models_dir,'MLPNet.{epoch:02d}-{val_loss:.2f}.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.2 Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_sched(epoch):\n",
    "    return 1/(1+lr_decay*epoch) * alpha#*(lr_decay**epoch)\n",
    "\n",
    "schd = LearningRateScheduler(lr_sched, verbose=1)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(filepath=modelpath, save_best_only=True, verbose=1, monitor='val_acc')\n",
    "tfboard = TensorBoard(log_dir='./logs', batch_size=128, write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "callbacks = [schd, early_stopping, model_checkpoint, tfboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.3 The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None#'MLPNet.28-0.08.hdf5'\n",
    "\n",
    "if model:\n",
    "    alpha = 0.004998650364401612\n",
    "    model = os.path.join('../models', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(path=None):        \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    if path:\n",
    "        return load_model(path)\n",
    "    \n",
    "    # layer 1\n",
    "    model.add(\n",
    "        Dense(1024, \n",
    "        bias_initializer='zeros', kernel_initializer=he_uniform(seed), \n",
    "        kernel_regularizer=l2(lambd),\n",
    "        input_dim=784)\n",
    "    )\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # layer 1\n",
    "    model.add(\n",
    "        Dense(1024, \n",
    "        bias_initializer='zeros', kernel_initializer=he_uniform(seed), \n",
    "        kernel_regularizer=l2(lambd),\n",
    "        )\n",
    "    )\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    adam_optimizer = Adam(lr=alpha)\n",
    "    model.compile(optimizer=adam_optimizer, loss=loss, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.4 Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history=model.fit(trainX, trainY, batch_size=batch_size, epochs=num_epoch, verbose=1, \n",
    "                  callbacks=callbacks, validation_split=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.3 Best Model Yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
